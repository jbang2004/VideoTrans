This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: core/*.py, services/cosyvoice/*.py, services/cosyvoice/proto/*.proto
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
core/
  __init__.py
  audio_gener.py
  model_in.py
  tts_token_gener.py
services/
  cosyvoice/
    proto/
      cosyvoice.proto
    cache.py
    client.py
    service.py

================================================================
Files
================================================================

================
File: core/__init__.py
================
# 空文件即可，标识这是一个 Python 包

================
File: core/audio_gener.py
================
# core/audio_gener.py

import logging
import asyncio
import numpy as np
from typing import List
from services.cosyvoice.client import CosyVoiceClient
from utils import concurrency

class AudioGenerator:
    def __init__(self, cosyvoice_client: CosyVoiceClient, sample_rate: int = 24000):
        self.cosyvoice_client = cosyvoice_client
        self.sample_rate = sample_rate
        self.logger = logging.getLogger(__name__)

    async def vocal_audio_maker(self, sentences: List):
        """
        并发生成音频
        """
        tasks = []
        for s in sentences:
            if 'uuid' not in s.model_input:
                self.logger.warning("句子缺少UUID，无法生成音频")
                continue
            
            uuid = s.model_input.get('uuid')
            if not uuid:
                self.logger.warning("句子的UUID为空，无法生成音频")
                continue

            tasks.append(self._generate_single_async(s))

        try:
            results = await asyncio.gather(*tasks)
            return results
        except Exception as e:
            self.logger.error(f"音频生成失败: {str(e)}")
            raise

    async def _generate_single_async(self, sentence):
        try:
            final_audio = await concurrency.run_sync(self._generate_audio_single, sentence)
            sentence.generated_audio = final_audio
            return sentence
        except Exception as e:
            self.logger.error(
                f"音频生成失败 (UUID: {sentence.model_input.get('uuid', 'unknown')}): {str(e)}"
            )
            sentence.generated_audio = None
            return sentence

    def _generate_audio_single(self, sentence):
        """
        使用UUID从服务端获取音频
        """
        uuid = sentence.model_input.get('uuid')
        if not uuid:
            self.logger.warning("没有UUID，无法生成音频")
            return np.zeros(0, dtype=np.float32)

        speed = getattr(sentence, 'speed', 1.0) or 1.0
        audio_np, dur_sec = self.cosyvoice_client.token2wav(uuid, speed=speed)

        # 首段静音
        if getattr(sentence, 'is_first', False) and getattr(sentence, 'start', 0) > 0:
            silence_samples = int(sentence.start * self.sample_rate / 1000)
            audio_np = np.concatenate([
                np.zeros(silence_samples, dtype=np.float32),
                audio_np
            ])

        # 尾部留白
        if hasattr(sentence, 'silence_duration') and sentence.silence_duration > 0:
            silence_samples = int(sentence.silence_duration * self.sample_rate / 1000)
            audio_np = np.concatenate([
                audio_np,
                np.zeros(silence_samples, dtype=np.float32)
            ])

        self.logger.debug(
            f"音频生成完成 (UUID: {uuid}), "
            f"长度={len(audio_np)/self.sample_rate:.2f}s"
        )
        return audio_np

================
File: core/model_in.py
================
import logging
import asyncio
import torch
import numpy as np
import librosa
from typing import List, Dict
import os
import uuid
import soundfile as sf

from services.cosyvoice.client import CosyVoiceClient

class ModelIn:
    def __init__(self, cosyvoice_client: CosyVoiceClient, max_concurrent_tasks: int = 4):
        self.cosyvoice_client = cosyvoice_client
        self.logger = logging.getLogger(__name__)
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        # 缓存 speaker 特征提取任务，确保同一 speaker 只处理一次
        self.speaker_cache: Dict[str, asyncio.Task] = {}  # speaker_id -> asyncio.Task
        self.max_val = 0.8
        self.cosy_sample_rate = 24000

    def postprocess(self, speech, top_db=60, hop_length=220, win_length=440):
        """
        对音频进行 trim、幅度归一化，并在结尾加 0.2s 静音
        """
        speech, _ = librosa.effects.trim(
            speech,
            top_db=top_db,
            frame_length=win_length,
            hop_length=hop_length
        )
        if np.abs(speech).max() > self.max_val:
            speech = speech / np.abs(speech).max() * self.max_val

        # 结尾加 0.2s 静音
        pad_samples = int(self.cosy_sample_rate * 0.2)
        speech = np.concatenate([speech, np.zeros(pad_samples, dtype=speech.dtype)])
        return speech

    async def get_speaker_features(self, speaker_id: str, sentence) -> str:
        """
        异步提取 speaker 特征，并将任务缓存，
        确保同一 speaker 只处理一次。返回UUID。
        """
        if speaker_id in self.speaker_cache:
            return await self.speaker_cache[speaker_id]

        async def extract_features() -> str:
            # 获取音频数据
            audio_np = (
                sentence.audio.squeeze(0).cpu().numpy()
                if isinstance(sentence.audio, torch.Tensor)
                else sentence.audio
            )
            postprocessed_audio = self.postprocess(audio_np)
            postprocessed_tensor = torch.from_numpy(postprocessed_audio).unsqueeze(0)

            # 获取UUID并提取特征
            uuid = await asyncio.to_thread(
                self.cosyvoice_client.normalize_text,
                ""  # 空文本，只用于获取UUID
            )
            success = await asyncio.to_thread(
                self.cosyvoice_client.extract_speaker_features,
                uuid,
                postprocessed_tensor,
                self.cosy_sample_rate
            )
            if not success:
                raise Exception("提取说话人特征失败")
            return uuid

        task = asyncio.create_task(extract_features())
        self.speaker_cache[speaker_id] = task
        return await task

    async def _process_one_sentence_async(self, sentence, reuse_speaker: bool, reuse_uuid: bool):
        async with self.semaphore:
            speaker_id = getattr(sentence, 'speaker_id', None)
            
            # 处理UUID
            if not reuse_uuid:
                # 获取新的UUID
                uuid = await asyncio.to_thread(
                    self.cosyvoice_client.normalize_text,
                    sentence.trans_text or ""
                )
                sentence.model_input['uuid'] = uuid
            
            # speaker 特征提取
            if speaker_id is not None and not reuse_speaker:
                speaker_uuid = await self.get_speaker_features(speaker_id, sentence)
                sentence.model_input['speaker_uuid'] = speaker_uuid

            return sentence

    async def modelin_maker(self, sentences: List, reuse_speaker: bool = False, reuse_uuid: bool = False, batch_size: int = 3):
        """
        对一批 sentence 进行文本与 speaker 特征提取，
        并按 batch_size 分批 yield 结果。
        """
        if not sentences:
            self.logger.warning("modelin_maker: 收到空句子列表")
            return

        tasks = [
            asyncio.create_task(self._process_one_sentence_async(s, reuse_speaker, reuse_uuid))
            for s in sentences
        ]

        results_batch = []
        try:
            for i, task in enumerate(tasks, start=1):
                updated = await task
                if updated is not None:
                    results_batch.append(updated)
                if i % batch_size == 0:
                    yield results_batch
                    results_batch = []
            if results_batch:
                yield results_batch
        except Exception as e:
            self.logger.error(f"modelin_maker处理失败: {e}")
            raise
        finally:
            if not reuse_speaker:
                self.speaker_cache.clear()

================
File: core/tts_token_gener.py
================
# core/tts_token_gener.py

import logging
import asyncio
from typing import List
from services.cosyvoice.client import CosyVoiceClient
from utils import concurrency

class TTSTokenGenerator:
    def __init__(self, cosyvoice_client: CosyVoiceClient):
        self.cosyvoice_client = cosyvoice_client
        self.logger = logging.getLogger(__name__)

    async def tts_token_maker(self, sentences: List, reuse_uuid: bool = False):
        """
        并发生成TTS tokens，并存储预估时长
        """
        if not sentences:
            return []

        tasks = []
        for s in sentences:
            if not reuse_uuid and 'uuid' not in s.model_input:
                self.logger.warning("句子缺少UUID，无法生成TTS tokens")
                continue
            
            uuid = s.model_input.get('uuid')
            if not uuid:
                self.logger.warning("句子的UUID为空，无法生成TTS tokens")
                continue

            tasks.append(asyncio.create_task(self._generate_tts_single_async(s, uuid)))

        processed = await asyncio.gather(*tasks)
        return processed

    async def _generate_tts_single_async(self, sentence, uuid: str):
        return await concurrency.run_sync(
            self._generate_tts_single, sentence, uuid
        )

    def _generate_tts_single(self, sentence, uuid: str):
        # 生成TTS tokens并获取时长
        duration_ms, success = self.cosyvoice_client.generate_tts_tokens(uuid)
        if not success:
            self.logger.error(f"生成TTS tokens失败 (UUID={uuid})")
            return sentence

        sentence.duration = duration_ms
        self.logger.debug(f"[TTS Token] (UUID={uuid}) 生成完毕 => 估计时长 {duration_ms}ms")
        return sentence

    def _merge_features(self, text_f, speaker_f):
        merged = type(text_f)()
        # 拷贝 text_f
        merged.normalized_text_segments.extend(text_f.normalized_text_segments)
        for seg in text_f.text_segments:
            seg_msg = merged.text_segments.add()
            seg_msg.tokens.extend(seg.tokens)

        # 拷贝 speaker_f
        if speaker_f:
            merged.embedding.extend(speaker_f.embedding)
            merged.prompt_speech_feat.extend(speaker_f.prompt_speech_feat)
            merged.prompt_speech_feat_len = speaker_f.prompt_speech_feat_len
            merged.prompt_speech_token.extend(speaker_f.prompt_speech_token)
            merged.prompt_speech_token_len = speaker_f.prompt_speech_token_len

        return merged

================
File: services/cosyvoice/proto/cosyvoice.proto
================
syntax = "proto3";

package cosyvoice;

// ========== Service 定义 ==========
service CosyVoiceService {
  rpc NormalizeText (NormalizeTextRequest) returns (NormalizeTextResponse);
  rpc ExtractSpeakerFeatures (ExtractSpeakerFeaturesRequest) returns (ExtractSpeakerFeaturesResponse);
  rpc GenerateTTSTokens (GenerateTTSTokensRequest) returns (GenerateTTSTokensResponse);
  rpc Token2Wav (Token2WavRequest) returns (Token2WavResponse);
  rpc Cleanup (CleanupRequest) returns (CleanupResponse);
}

// ========== RPC 请求与响应 ==========

// 1) NormalizeText
message NormalizeTextRequest {
  string text = 1;
}

message NormalizeTextResponse {
  string uuid = 1;      // 返回生成的UUID
}

// 2) ExtractSpeakerFeatures
message ExtractSpeakerFeaturesRequest {
  string uuid = 1;      // 目标UUID
  bytes audio = 2;      // 音频数据
  int32 sample_rate = 3;
}

message ExtractSpeakerFeaturesResponse {
  bool success = 1;
}

// 3) GenerateTTSTokens
message GenerateTTSTokensRequest {
  string uuid = 1;      // 目标UUID
}

message GenerateTTSTokensResponse {
  int32 duration_ms = 1;
  bool success = 2;
}

// 4) Token2Wav
message Token2WavRequest {
  string uuid = 1;      // 目标UUID
  float speed = 2;
}

message Token2WavResponse {
  bytes audio = 1;
  float duration_sec = 2;
}

// 5) Cleanup
message CleanupRequest {
  string uuid = 1;      // 要清理的UUID
}

message CleanupResponse {
  bool success = 1;
}

================
File: services/cosyvoice/cache.py
================
import threading
from typing import Dict, Optional, List
import torch

class FeatureData:
    """服务端特征数据存储结构，直接存储模型输出的数据，保持原有维度"""
    def __init__(self):
        # 文本相关
        self.normalized_texts: List[str] = []
        self.text_tokens: List[torch.Tensor] = []  # [batch_size, seq_len]
        
        # 说话人相关 - 保持原有维度
        self.embedding: Optional[torch.Tensor] = None  # [1, embedding_dim]
        self.prompt_speech_feat: Optional[torch.Tensor] = None  # [1, time, 80]
        self.prompt_speech_feat_len: int = 0
        self.prompt_speech_token: Optional[torch.Tensor] = None  # [1, seq_len]
        self.prompt_speech_token_len: int = 0
        
        # TTS tokens
        self.tts_tokens: List[List[int]] = []  # 直接存储模型生成的token列表
        self.tts_segment_uuids: List[str] = []

class FeaturesCache:
    def __init__(self):
        self._cache: Dict[str, FeatureData] = {}
        self._lock = threading.Lock()
    
    def get(self, uuid: str) -> Optional[FeatureData]:
        """获取特征数据"""
        with self._lock:
            return self._cache.get(uuid)
    
    def set(self, uuid: str, data: FeatureData) -> None:
        """设置特征数据"""
        with self._lock:
            self._cache[uuid] = data
    
    def update_text_features(self, uuid: str, normalized_texts: List[str], text_tokens: List[torch.Tensor]) -> bool:
        """更新文本特征，text_tokens应该已经是正确的维度 [batch_size, seq_len]"""
        with self._lock:
            if uuid not in self._cache:
                data = FeatureData()
                data.normalized_texts = normalized_texts
                data.text_tokens = text_tokens
                self._cache[uuid] = data
            else:
                self._cache[uuid].normalized_texts = normalized_texts
                self._cache[uuid].text_tokens = text_tokens
            return True
    
    def update_speaker_features(self, uuid: str, 
                              embedding: torch.Tensor,  # [1, embedding_dim]
                              prompt_feat: torch.Tensor,  # [1, time, 80]
                              prompt_feat_len: int,
                              prompt_token: torch.Tensor,  # [1, seq_len]
                              prompt_token_len: int) -> bool:
        """更新说话人特征，保持输入tensor的原有维度"""
        with self._lock:
            if uuid not in self._cache:
                return False
            data = self._cache[uuid]
            data.embedding = embedding
            data.prompt_speech_feat = prompt_feat
            data.prompt_speech_feat_len = prompt_feat_len
            data.prompt_speech_token = prompt_token
            data.prompt_speech_token_len = prompt_token_len
            return True
    
    def update_tts_tokens(self, uuid: str, tokens: List[List[int]], segment_uuids: List[str]) -> bool:
        """更新TTS tokens"""
        with self._lock:
            if uuid not in self._cache:
                return False
            data = self._cache[uuid]
            data.tts_tokens = tokens
            data.tts_segment_uuids = segment_uuids
            return True
    
    def delete(self, uuid: str) -> None:
        """删除特征数据"""
        with self._lock:
            self._cache.pop(uuid, None)
    
    def exists(self, uuid: str) -> bool:
        """检查UUID是否存在"""
        with self._lock:
            return uuid in self._cache

================
File: services/cosyvoice/client.py
================
import grpc
import numpy as np
import torch
import logging
from typing import Tuple, Optional

from .proto import cosyvoice_pb2
from .proto import cosyvoice_pb2_grpc

logger = logging.getLogger(__name__)

class CosyVoiceClient:
    def __init__(self, address="localhost:50052"):
        self.channel = grpc.insecure_channel(address)
        self.stub = cosyvoice_pb2_grpc.CosyVoiceServiceStub(self.channel)

    def normalize_text(self, text: str) -> str:
        """
        文本标准化，返回UUID
        """
        try:
            req = cosyvoice_pb2.NormalizeTextRequest(text=text)
            resp = self.stub.NormalizeText(req)
            return resp.uuid
        except Exception as e:
            logger.error(f"NormalizeText调用失败: {e}")
            raise

    def extract_speaker_features(self, uuid: str, audio_tensor: torch.Tensor, sr: int = 24000) -> bool:
        """
        提取说话人特征并更新服务端缓存
        """
        try:
            audio_np = audio_tensor.squeeze(0).cpu().numpy()
            req = cosyvoice_pb2.ExtractSpeakerFeaturesRequest(
                uuid=uuid,
                audio=audio_np.tobytes(),
                sample_rate=sr
            )
            resp = self.stub.ExtractSpeakerFeatures(req)
            return resp.success
        except Exception as e:
            logger.error(f"ExtractSpeakerFeatures调用失败: {e}")
            raise

    def generate_tts_tokens(self, uuid: str) -> Tuple[int, bool]:
        """
        生成TTS tokens并返回预估时长
        """
        try:
            req = cosyvoice_pb2.GenerateTTSTokensRequest(uuid=uuid)
            resp = self.stub.GenerateTTSTokens(req)
            return resp.duration_ms, resp.success
        except Exception as e:
            logger.error(f"GenerateTTSTokens调用失败: {e}")
            raise

    def token2wav(self, uuid: str, speed: float = 1.0) -> Tuple[np.ndarray, float]:
        """
        将TTS tokens转换为音频
        """
        try:
            req = cosyvoice_pb2.Token2WavRequest(uuid=uuid, speed=speed)
            resp = self.stub.Token2Wav(req)
            audio_np = np.frombuffer(resp.audio, dtype=np.int16).astype(np.float32) / (2**15)
            return audio_np, resp.duration_sec
        except Exception as e:
            logger.error(f"Token2Wav调用失败: {e}")
            raise

    def cleanup(self, uuid: str) -> bool:
        """
        清理服务端缓存
        """
        try:
            req = cosyvoice_pb2.CleanupRequest(uuid=uuid)
            resp = self.stub.Cleanup(req)
            return resp.success
        except Exception as e:
            logger.error(f"Cleanup调用失败: {e}")
            raise

================
File: services/cosyvoice/service.py
================
# services/cosyvoice/service.py

import logging
import numpy as np
import torch
import grpc
from concurrent import futures
import uuid

from .proto import cosyvoice_pb2
from .proto import cosyvoice_pb2_grpc
from .cache import FeaturesCache, FeatureData

# 假设我们使用 CosyVoice2 作为模型
from models.CosyVoice.cosyvoice.cli.cosyvoice import CosyVoice2

logger = logging.getLogger(__name__)

class CosyVoiceServiceServicer(cosyvoice_pb2_grpc.CosyVoiceServiceServicer):
    def __init__(self, model_path="models/CosyVoice/pretrained_models/CosyVoice2-0.5B"):
        try:
            self.cosyvoice = CosyVoice2(model_path)
            self.frontend = self.cosyvoice.frontend
            self.model = self.cosyvoice.model
            self.sample_rate = self.cosyvoice.sample_rate
            self.cache = FeaturesCache()
            logger.info('CosyVoice服务初始化成功')
        except Exception as e:
            logger.error(f'CosyVoice服务初始化失败: {e}')
            raise

    def _generate_uuid(self) -> str:
        """生成唯一的UUID"""
        return str(uuid.uuid4())

    def NormalizeText(self, request, context):
        """
        文本标准化，生成特征数据并缓存
        """
        try:
            text = request.text or ""
            normalized_texts = self.frontend.text_normalize(text, split=True, text_frontend=True)
            text_tokens = []
            
            # 提取文本tokens，保持原有维度
            for seg in normalized_texts:
                tokens, _ = self.frontend._extract_text_token(seg)  # 已经是 [batch_size, seq_len]
                text_tokens.append(tokens)

            # 生成UUID并缓存特征
            new_uuid = self._generate_uuid()
            self.cache.update_text_features(new_uuid, normalized_texts, text_tokens)

            return cosyvoice_pb2.NormalizeTextResponse(uuid=new_uuid)
        except Exception as e:
            logger.error(f"NormalizeText失败: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return cosyvoice_pb2.NormalizeTextResponse()

    def ExtractSpeakerFeatures(self, request, context):
        """
        提取说话人特征并更新缓存
        """
        try:
            uuid = request.uuid
            if not self.cache.exists(uuid):
                context.set_code(grpc.StatusCode.NOT_FOUND)
                context.set_details(f"UUID {uuid} 不存在")
                return cosyvoice_pb2.ExtractSpeakerFeaturesResponse()

            # 处理音频数据
            audio_np = np.frombuffer(request.audio, dtype=np.float32).copy()
            audio = torch.from_numpy(audio_np).unsqueeze(0)  # [1, T]

            # 提取特征 - 直接使用模型输出的tensor，维度已经正确
            result = self.frontend.frontend_cross_lingual("", audio, request.sample_rate)
            
            # 更新缓存 - 直接存储tensor，维度已经正确
            success = self.cache.update_speaker_features(
                uuid,
                embedding=result['llm_embedding'],  # [1, embedding_dim]
                prompt_feat=result['prompt_speech_feat'],  # [1, time, 80]
                prompt_feat_len=int(result['prompt_speech_feat_len'].item()),
                prompt_token=result['flow_prompt_speech_token'],  # [1, seq_len]
                prompt_token_len=int(result['flow_prompt_speech_token_len'].item())
            )

            if not success:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details("更新缓存失败")
                return cosyvoice_pb2.ExtractSpeakerFeaturesResponse()

            return cosyvoice_pb2.ExtractSpeakerFeaturesResponse(success=True)
        except Exception as e:
            logger.error(f"ExtractSpeakerFeatures失败: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return cosyvoice_pb2.ExtractSpeakerFeaturesResponse()

    def GenerateTTSTokens(self, request, context):
        """
        生成TTS tokens并更新缓存
        """
        try:
            uuid = request.uuid
            features = self.cache.get(uuid)
            if not features:
                context.set_code(grpc.StatusCode.NOT_FOUND)
                context.set_details(f"UUID {uuid} 不存在")
                return cosyvoice_pb2.GenerateTTSTokensResponse()

            total_duration_ms = 0
            tts_tokens = []
            segment_uuids = []

            # 处理每段文本
            for i, text_tokens in enumerate(features.text_tokens):
                seg_uuid = f"{uuid}_seg_{i}"
                segment_uuids.append(seg_uuid)

                # 初始化LLM状态
                self.model.tts_speech_token_dict[seg_uuid] = []
                self.model.llm_end_dict[seg_uuid] = False

                try:
                    # 生成TTS tokens，使用默认空特征值替换不存在的特征
                    self.model.llm_job(
                        text=text_tokens,
                        prompt_text=torch.zeros(1, 0, dtype=torch.int32),
                        llm_prompt_speech_token=features.prompt_speech_token if features.prompt_speech_token is not None 
                            else torch.zeros(1, 0, dtype=torch.int32),
                        llm_embedding=features.embedding if features.embedding is not None 
                            else torch.zeros(0, 192),
                        uuid=seg_uuid
                    )

                    # 获取生成的tokens
                    seg_tokens = self.model.tts_speech_token_dict[seg_uuid]
                    tts_tokens.append(seg_tokens)

                    # 估算时长
                    total_duration_ms += len(seg_tokens) / 25.0 * 1000

                finally:
                    # 清理LLM状态
                    self.model.tts_speech_token_dict.pop(seg_uuid, None)
                    self.model.llm_end_dict.pop(seg_uuid, None)

            # 更新缓存
            success = self.cache.update_tts_tokens(uuid, tts_tokens, segment_uuids)
            if not success:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details("更新缓存失败")
                return cosyvoice_pb2.GenerateTTSTokensResponse()

            return cosyvoice_pb2.GenerateTTSTokensResponse(
                duration_ms=int(total_duration_ms),
                success=True
            )

        except Exception as e:
            logger.error(f"GenerateTTSTokens失败: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return cosyvoice_pb2.GenerateTTSTokensResponse()

    def Token2Wav(self, request, context):
        """
        将缓存中的TTS tokens转换为音频
        """
        try:
            uuid = request.uuid
            features = self.cache.get(uuid)
            if not features:
                context.set_code(grpc.StatusCode.NOT_FOUND)
                context.set_details(f"UUID {uuid} 不存在")
                return cosyvoice_pb2.Token2WavResponse()

            speed = request.speed
            audio_pieces = []
            total_duration_sec = 0.0

            # 处理每个TTS segment
            for seg_tokens, seg_uuid in zip(features.tts_tokens, features.tts_segment_uuids):
                if not seg_tokens:
                    continue

                # 设置缓存
                self.model.hift_cache_dict[seg_uuid] = None
                try:
                    # 使用默认空特征值替换不存在的特征
                    seg_audio_out = self.model.token2wav(
                        token=torch.tensor(seg_tokens).unsqueeze(0),
                        prompt_token=features.prompt_speech_token if features.prompt_speech_token is not None 
                            else torch.zeros(1, 0, dtype=torch.int32),
                        prompt_feat=features.prompt_speech_feat if features.prompt_speech_feat is not None 
                            else torch.zeros(1, 0, 80),
                        embedding=features.embedding if features.embedding is not None 
                            else torch.zeros(0),
                        uuid=seg_uuid,
                        token_offset=0,
                        finalize=True,
                        speed=speed
                    )
                finally:
                    self.model.hift_cache_dict.pop(seg_uuid, None)

                # 处理音频
                seg_audio = seg_audio_out.cpu().numpy().squeeze()
                if seg_audio.ndim > 1:
                    seg_audio = seg_audio.mean(axis=0)
                audio_pieces.append(seg_audio)
                total_duration_sec += len(seg_audio) / self.sample_rate

            if not audio_pieces:
                logger.warning(f"Token2Wav: UUID {uuid} 未生成任何音频")
                return cosyvoice_pb2.Token2WavResponse()

            # 合并音频
            final_audio = np.concatenate(audio_pieces)
            audio_int16 = (final_audio * (2**15)).astype(np.int16).tobytes()

            return cosyvoice_pb2.Token2WavResponse(
                audio=audio_int16,
                duration_sec=total_duration_sec
            )

        except Exception as e:
            logger.error(f"Token2Wav失败: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return cosyvoice_pb2.Token2WavResponse()

    def Cleanup(self, request, context):
        """
        清理缓存中的特征数据
        """
        try:
            uuid = request.uuid
            self.cache.delete(uuid)
            return cosyvoice_pb2.CleanupResponse(success=True)
        except Exception as e:
            logger.error(f"Cleanup失败: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return cosyvoice_pb2.CleanupResponse(success=False)

def serve(args):
    host = getattr(args, 'host', '0.0.0.0')
    port = getattr(args, 'port', 50052)
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    cosyvoice_pb2_grpc.add_CosyVoiceServiceServicer_to_server(
        CosyVoiceServiceServicer(args.model_dir), server
    )
    address = f'{host}:{port}'
    server.add_insecure_port(address)
    server.start()
    logger.info(f'CosyVoice服务已启动: {address}')
    server.wait_for_termination()



================================================================
End of Codebase
================================================================
